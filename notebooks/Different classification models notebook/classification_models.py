# -*- coding: utf-8 -*-
"""classification_models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jm1JP7ftU07UVe0iMhVbX08wWwrdAw1Q
"""

from google.colab import drive
drive.mount('/content/drive')

"""#Import Data"""

# get data from kaggle
!pip install kaggle
!mkdir ~/.kaggle

import kagglehub

# Download latest version
path = kagglehub.dataset_download("talaviyabhavik/customer-support-training-data")

print("Path to dataset files:", path)

"""# General EDA"""

# get csv file for data
import pandas as pd
file_path = '/root/.cache/kagglehub/datasets/talaviyabhavik/customer-support-training-data/versions/1/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11 (1).csv'
df = pd.read_csv(file_path)
df.head()

df = df.drop(['flags', 'response'], axis=1)

df['intent'].unique()

df['intent'].value_counts()

df['instruction'].value_counts()

df['instruction'].iloc[100]

df.rename(columns={'instruction': 'description'}, inplace=True)

# Select the intentes you want to concatenate them with the main Category
categories_intents = {"ACCOUNT":['registration_problems' , 'recover_password'] , "FEEDBACK" : ["complaint","review"]}

def concatenate_intents(categories_intents,text) :
  for category,intent in categories_intents.items() :
    if text in intent :
        # print(text,intent,category)
        category = category.lower()
        text = category+"_"+text
        # print(intent)
    else :
      continue

  return text


df['new_intent'] = df['intent'].apply(lambda x : concatenate_intents(categories_intents,x))

df.head()

df  = df[["new_intent",'description']]

df.shape

# Drop nulls and duplicates
df.dropna(inplace=True)
df.drop_duplicates(inplace=True)

df.shape

"""#NLP Preprocessing"""

df.head()

for i in df['new_intent'].unique():
  print(i + ': ' + str(df[df['new_intent'] == i].shape[0]))
  print(df[df['new_intent'] == i]['description'].iloc[100])
  print()

!pip install contractions
# Download 'wordnet' dataset
# Install the textblob package
import nltk
nltk.download('wordnet')
nltk.download('punkt') # Download the 'punkt' resource for sentence tokenization
nltk.download('punkt_tab')
nltk.download('stopwords')
!pip install textblob

# üîπ 1. Advanced Text Preprocessing Function

import contractions
import regex as re
import string
import nltk # Import nltk
from nltk.tokenize import word_tokenize # Import word_tokenize
from nltk.corpus import stopwords # Import stopwords
from nltk.stem import WordNetLemmatizer # Import WordNetLemmatizer
from textblob import TextBlob # Import TextBlob
from sklearn.model_selection import train_test_split # Import train_test_split


def clean_text_advanced(text):
    # Expand contractions
    text = contractions.fix(text)

    # Lowercase
    text = text.lower()

    # Remove digits and punctuation
    text = re.sub(r'\{\{.*?\}\}', '', text)

    text = text.split()
    text = ' '.join(text)
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)

     # Tokenize text
    tokens = word_tokenize(text)
    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    essential_words = {'not', 'no', 'cannot'}
    custom_stop_words = stop_words - essential_words
    tokens = [word for word in tokens if word not in custom_stop_words]


    # Lemmatize tokens
    lemmatizer = WordNetLemmatizer()
    lemmatized_tokens = [lemmatizer.lemmatize(token,pos='v') for token in tokens]
    lemmatized_tokens = [lemmatizer.lemmatize(token, pos ='v') for token in tokens]
    lemmatized_tokens = [lemmatizer.lemmatize(token, pos ='a') for token in tokens]
    lemmatized_tokens = [lemmatizer.lemmatize(token, pos ='r') for token in tokens]
    lemmatized_tokens = [lemmatizer.lemmatize(token, pos ='s') for token in tokens]
    lemmatized_tokens = [lemmatizer.lemmatize(token, pos ='n') for token in tokens]

    # Join tokens back into a string
    cleaned_text = ' '.join(lemmatized_tokens)

    # Optional: Spell correction (can slow down processing)
    cleaned_text = str(TextBlob(cleaned_text).correct()) # Now TextBlob is defined

    # # Spell correction (optional - slow on large datasets)
    # text = str(TextBlob(text).correct())

    return cleaned_text
# Apply preprocessing
df['cleaned_description'] = df['description'].apply(clean_text_advanced)

# Splitting data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    df['cleaned_description'], df['new_intent'], test_size=0.2, random_state=42)

# Display the preprocessed dataset
print(df.head())

df.to_csv('/content/cleaned_data.csv', index=False)

import os

# Create the directory
os.makedirs('/content/drive/My Drive/cleaned_data', exist_ok=True)

#save the DataFrame to CSV
df.to_csv('/content/drive/My Drive/cleaned_data/cleaned_customer_support_data.csv', index=False)

for i in df['new_intent'].unique():
  print(i)
  print(df[df['new_intent'] == i]['cleaned_description'].iloc[100])
  print()

"""# label encoder"""

from sklearn.preprocessing import LabelEncoder # Import LabelEncoder

label_encoder = LabelEncoder()
y_train_enc = label_encoder.fit_transform(y_train)
y_test_enc = label_encoder.transform(y_test)

label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))

# Print mapping of categories to numbers
print("Label Encoding Mapping:")
print(label_mapping)

"""# TF-IDF Vectorization
Feature Extraction using TF-IDF vectorization to transform the cleaned text into numerical features. The training (X_train_tfidf) and testing (X_test_tfidf)
"""

from sklearn.feature_extraction.text import TfidfVectorizer
# TF-IDF Vectorization
tfidf_vectorizer = TfidfVectorizer()
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)
print(X_train_tfidf.shape)
print(X_test_tfidf.shape)
print(y_train.shape)
print(y_test.shape)
# print(X_train_tfidf)

"""# Model Training & Evaluation

## Traditional ML models first:

Logistic Regression

Support Vector Machine (SVM)

Random Forest

Na√Øve Bayes
"""

from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import SGDClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Initialize models
models = {
    # Reproducible models (random_state set)
    'Logistic Regression': LogisticRegression(random_state=42),
    'SVM': SVC(probability=True, random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'SGD': SGDClassifier(loss='log_loss', random_state=42),

    # Na√Øve Bayes (no random_state)
    'Na√Øve Bayes': MultinomialNB()
}

# Train and evaluate each model
for name, model in models.items():
    model.fit(X_train_tfidf, y_train)
    y_train_pred = model.predict(X_train_tfidf)
    y_pred = model.predict(X_test_tfidf)
    print(f"\n{name} Accuracy for train : {accuracy_score(y_train, y_train_pred):.4f}")
    print(f"\n{name} Accuracy for test : {accuracy_score(y_test, y_pred):.4f}")
    print(f"{name} Classification Report:")
    print(classification_report(y_test, y_pred))

import joblib
import os # Import the os module

# Save each ML model
for name, model in models.items():
    # Create the directory
    os.makedirs("/content/drive/MyDrive/models4/", exist_ok=True)
    joblib.dump(model, f"/content/drive/MyDrive/models4/{name}.pkl")
    print(f"Saved {name} model to Drive.")

# Save TF-IDF Vectorizer
joblib.dump(tfidf_vectorizer, "/content/drive/MyDrive/models4/tfidf_vectorizer.pkl")

# Load ML Models
ml_models = {
    "Logistic Regression": joblib.load("/content/drive/MyDrive/models4/Logistic Regression.pkl"),
    "SVM": joblib.load("/content/drive/MyDrive/models4/SVM.pkl"),
    "Random Forest": joblib.load("/content/drive/MyDrive/models4/Random Forest.pkl"),
    "SGD": joblib.load("/content/drive/MyDrive/models4/SGD.pkl"),
    "Na√Øve Bayes": joblib.load("/content/drive/MyDrive/models4/Na√Øve Bayes.pkl")
}

# Load TF-IDF Vectorizer
tfidf_vectorizer = joblib.load("/content/drive/MyDrive/models4/tfidf_vectorizer.pkl")

# Function to preprocess and predict
def predict_category(text, model_name="Logistic Regression"):
    """
    Preprocesses text and predicts the category using the specified model.

    Args:
        text (str): The input text.
        model_name (str, optional): The name of the model to use.
                                     Defaults to "Logistic Regression".

    Returns:
        str: The predicted category.
    """
    # Preprocess the text
    processed_text = clean_text_advanced(text)

    # Transform using TF-IDF
    text_tfidf = tfidf_vectorizer.transform([processed_text])

    # Get the specified model
    model = ml_models[model_name]

    # Make the prediction
    prediction = model.predict(text_tfidf)[0]

    return prediction

# Example usage:
new_text = "I need help with my order"
predicted_category = predict_category(new_text, model_name="Random Forest")
print(f"Predicted Category: {predicted_category}")

"""## Deep Learning models"""

from sklearn.preprocessing import LabelEncoder
# Convert labels to categorical
label_encoder = LabelEncoder()
y_train_enc = label_encoder.fit_transform(y_train)
y_test_enc = label_encoder.transform(y_test)

"""### LSTM (Long Short-Term Memory)

LSTM model : tokenizes the text, pads sequences, trains an LSTM network, and evaluates accuracy.

---



*   Instead of using pd.factorize(), use LabelEncoder to ensure consistency

*  Modify the model to include Dropout layers and L2 Regularization to Reduce Overfitting
*   Use More Epochs with Early Stopping




---
"""

import tensorflow as tf
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D
from tensorflow.keras.regularizers import l2
from tensorflow.keras.layers import Dropout
from tensorflow.keras.callbacks import EarlyStopping

# Deep Learning - LSTM Model
max_words = 5000  # Vocabulary size
max_len = 100  # Maximum length of a sequence

tokenizer = Tokenizer(num_words=max_words, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)
X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_len)
X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_len)

# Convert labels to categorical
label_encoder = LabelEncoder()
y_train_enc = label_encoder.fit_transform(y_train)
y_test_enc = label_encoder.transform(y_test)

# Build LSTM Model
lstm_model = Sequential([
    Embedding(max_words, 128, input_length=max_len),
    SpatialDropout1D(0.2),
    LSTM(100, dropout=0.3, recurrent_dropout=0.3, kernel_regularizer=l2(0.01)),  # L2 regularization
    Dropout(0.3),  # Additional dropout
    Dense(len(set(y_train)), activation='softmax', kernel_regularizer=l2(0.01))  # Apply L2 regularization
])

lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train LSTM Model
# lstm_model.fit(X_train_seq, y_train_cat, epochs=5, batch_size=32, validation_data=(X_test_seq, y_test_cat))
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

lstm_model.fit(
    X_train_seq, y_train_enc,
    epochs=20,
    batch_size=32,
    validation_data=(X_test_seq, y_test_enc),
    callbacks=[early_stop]
)

# Evaluate LSTM Model
y_pred_lstm = lstm_model.predict(X_test_seq).argmax(axis=1)

# Add this import at the top of the cell
from sklearn.metrics import accuracy_score, classification_report

print("\nLSTM Accuracy:", accuracy_score(y_test_enc, y_pred_lstm))
print(classification_report(y_test_enc, y_pred_lstm))

import tensorflow as tf
import pickle

# Save LSTM Model
lstm_model.save("/content/drive/MyDrive/models2/lstm_model.h5")

# Save Tokenizer
with open("/content/drive/MyDrive/models2/tokenizer.pkl", "wb") as handle:
    pickle.dump(tokenizer, handle)

# Save Label Encoder
with open("/content/drive/MyDrive/models2/label_encoder.pkl", "wb") as handle:
    pickle.dump(label_encoder, handle)

print("‚úÖ Models, tokenizer, and label encoder saved successfully!")

"""### Transformers (BERT)"""

!pip install transformers tensorflow

from transformers import BertTokenizer, TFBertForSequenceClassification
import numpy as np
from transformers import AdamWeightDecay
import tensorflow as tf

# Transformer-based BERT Model
tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased')


def encode_texts(texts):
    encoded = tokenizer_bert(texts.tolist(), padding=True, truncation=True, max_length=100, return_tensors="tf")
    return encoded['input_ids'], encoded['attention_mask']


X_train_input_ids, X_train_attention_mask = encode_texts(X_train)
X_test_input_ids, X_test_attention_mask = encode_texts(X_test)


bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(set(y_train)), from_pt=True)

optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)
bert_model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])

# Train BERT Model


bert_model.fit(
    [X_train_input_ids, X_train_attention_mask],
    y_train_enc,
    epochs=6, batch_size=16,
    validation_data=([X_test_input_ids, X_test_attention_mask], y_test_enc)
)

import numpy as np
# Evaluate BERT Model
y_pred_bert = np.argmax(bert_model.predict([X_test_input_ids, X_test_attention_mask]).logits, axis=1)
print("\nBERT Accuracy:", accuracy_score(y_test_enc, y_pred_bert))

# Save BERT Model
bert_model.save_pretrained("/content/drive/My Drive/models2/bert_model_10")
tokenizer_bert.save_pretrained("/content/drive/My Drive/models2/bert_tokenizer_10")
print("Saved BERT model and tokenizer to Drive.")

from transformers import BertTokenizer, TFBertForSequenceClassification
# Load Tokenizer & Model
tokenizer_bert = BertTokenizer.from_pretrained("/content/drive/MyDrive/models2/bert_tokenizer_10")
bert_model = TFBertForSequenceClassification.from_pretrained("/content/drive/MyDrive/models2/bert_model_10")
print("Loaded BERT model and tokenizer from Drive.")

"""# make predictions on new tickets."""

import joblib # Import the joblib library

# Load ML Models
ml_models = {
    "Logistic Regression": joblib.load("/content/drive/MyDrive/models4/Logistic Regression.pkl"),
    "SVM": joblib.load("/content/drive/MyDrive/models4/SVM.pkl"),
    "SGD": joblib.load("/content/drive/MyDrive/models4/SGD.pkl"),
    "Random Forest": joblib.load("/content/drive/MyDrive/models4/Random Forest.pkl"),
    "Na√Øve Bayes": joblib.load("/content/drive/MyDrive/models4/Na√Øve Bayes.pkl")
}

# Load TF-IDF Vectorizer
tfidf_vectorizer = joblib.load("/content/drive/MyDrive/models4/tfidf_vectorizer.pkl")

def predict_with_ml(text):
    text_tfidf = tfidf_vectorizer.transform([text])
    predictions = {name: model.predict(text_tfidf)[0] for name, model in ml_models.items()}
    return predictions


new_ticket = [
        "I want to cancel my order and get a refund because I never received it.",
        "Can you help me track my recent order? Also, I need to change my shipping address.",
        "I forgot my password and now my payment isn't going through. Help!",
        "Where can I see available delivery options? Also, I'd like to delete my account permanently.",
        "I tried to contact support, but no human agent responded. My payment also failed!",
]
ml_predictions = [predict_with_ml(ticket) for ticket in new_ticket]

print("ML Model Predictions:", ml_predictions)

!pip install tensorflow

import tensorflow as tf
import pickle
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load Tokenizer & Label Encoder
with open("/content/drive/MyDrive/models2/tokenizer.pkl", "rb") as handle:
    tokenizer = pickle.load(handle)

with open("/content/drive/MyDrive/models2/label_encoder.pkl", "rb") as handle:
    label_encoder = pickle.load(handle)

# Load Trained Models
lstm_model = tf.keras.models.load_model("/content/drive/MyDrive/models2/lstm_model.h5")


print("‚úÖ Models, tokenizer, and label encoder loaded successfully!")

# Function to Predict with Deep Learning Models
def predict_with_dl(model, text):
    seq = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=100)
    pred_index = model.predict(seq).argmax(axis=1)
    pred_label = label_encoder.inverse_transform(pred_index)
    return pred_label[0]  # Extract string label

# Example Prediction
new_ticket = [
        "I want to cancel my order and get a refund because I never received it.",
        "Can you help me track my recent order? Also, I need to change my shipping address.",
        "I forgot my password and now my payment isn't going through. Help!",
        "Where can I see available delivery options? Also, I'd like to delete my account permanently.",
        "I tried to contact support, but no human agent responded. My payment also failed!",
]

lstm_prediction =[predict_with_dl(lstm_model, ticket) for ticket in new_ticket]


print("LSTM Prediction:", lstm_prediction)

!pip install tf-keras

from transformers import BertTokenizer, TFBertForSequenceClassification
import numpy as np

# Load Tokenizer & Model
tokenizer_bert = BertTokenizer.from_pretrained("/content/drive/MyDrive/models2/bert_tokenizer_10")
bert_model = TFBertForSequenceClassification.from_pretrained("/content/drive/MyDrive/models2/bert_model_10")

def predict_with_bert(text):
    inputs = tokenizer_bert([text], padding=True, truncation=True, max_length=100, return_tensors="tf")
    logits = bert_model(inputs["input_ids"]).logits
    pred1 = np.argmax(logits, axis=1)
    pred = label_encoder.inverse_transform(pred1)
    return pred

new_ticket = [
        "I want to cancel my order and get a refund because I never received it.",
        "Can you help me track my recent order? Also, I need to change my shipping address.",
        "I forgot my password and now my payment isn't going through. Help!",
        "Where can I see available delivery options? Also, I'd like to delete my account permanently.",
        "I tried to contact support, but no human agent responded. My payment also failed!",
]
bert_prediction = [predict_with_bert(ticket) for ticket in new_ticket]
print("BERT Prediction:", bert_prediction)

import pandas as pd
import numpy as np

# Assuming ml_predictions is a list of dictionaries
ml_predictions_df = pd.DataFrame(ml_predictions)  # Convert ml_predictions to DataFrame

# Convert other lists to DataFrames with appropriate column names
bert_prediction_df = pd.DataFrame(bert_prediction, columns=['BERT'])
lstm_prediction_df = pd.DataFrame(lstm_prediction, columns=['LSTM'])

# Create a DataFrame with the original tickets
tickets_df = pd.DataFrame(new_ticket, columns=['Ticket'])
correct_df = pd.DataFrame({'correct':[
        ["cancel_order", "get_refund"],
        ["track_order", "change_shipping_address"],
        ["account_recover_password", "payment_issue"],
        ["delivery_options", "delete_account"],
        ["contact_human_agent", "payment_issue"]

]})



# Now concatenate all the DataFrames
all_predictions_df = pd.concat([tickets_df, correct_df,bert_prediction_df, lstm_prediction_df, ml_predictions_df], axis=1)

# 1. Add "(correct)" or "(not found)"
for col in ['BERT', 'LSTM', *ml_predictions_df.columns]:  # Include all prediction columns
    all_predictions_df[col] = all_predictions_df.apply(
        lambda row: row[col] + ' (correct)' if row[col] in row['correct'] else row[col] + ' (not found)',
        axis=1
    )

# 2. Calculate and add accuracy row
accuracy_row = {'Ticket': 'Accuracy'}
for col in ['BERT', 'LSTM', *ml_predictions_df.columns]:
    accuracy = (all_predictions_df[col].str.contains('(correct)').sum() / len(all_predictions_df)) * 100
    accuracy_row[col] = f"{accuracy:.2f}%"

all_predictions_df = pd.concat([all_predictions_df, pd.DataFrame([accuracy_row])], ignore_index=True)

# Display the DataFrame
print(all_predictions_df)
all_predictions_df.to_csv('all_predictions.csv')

"""# Thinking and planning for multiclass"""

import joblib
import numpy as np

# Load ML Models
ml_models = {
    "Logistic Regression": joblib.load("/content/drive/MyDrive/models4/Logistic Regression.pkl"),
    "SVM": joblib.load("/content/drive/MyDrive/models4/SVM.pkl"),
    "SGD": joblib.load("/content/drive/MyDrive/models4/SGD.pkl"),
    "Random Forest": joblib.load("/content/drive/MyDrive/models4/Random Forest.pkl"),
    "Na√Øve Bayes": joblib.load("/content/drive/MyDrive/models4/Na√Øve Bayes.pkl")
}

# Load TF-IDF Vectorizer
tfidf_vectorizer = joblib.load("/content/drive/MyDrive/models4/tfidf_vectorizer.pkl")

def predict_with_ml(text):
    """
    Predict the category of a ticket using multiple ML models.
    Returns both predicted labels and probability scores.
    """
    text_tfidf = tfidf_vectorizer.transform([text])
    predictions = {}

    for name, model in ml_models.items():
        if hasattr(model, "predict_proba"):  # Models supporting probability prediction
            probs = model.predict_proba(text_tfidf)[0]
        elif hasattr(model, "decision_function"):  # SVM uses decision scores
            probs = model.decision_function(text_tfidf)
            probs = np.exp(probs) / np.sum(np.exp(probs))  # Softmax normalization for comparability
        else:
            probs = None  # Model does not support probabilities

        predicted_label = model.predict(text_tfidf)[0]

        # Store results
        predictions[name] = {
            "predicted_label": predicted_label,
            "probabilities": probs.tolist() if probs is not None else "Not Available"
        }

    return predictions

# Test on long multi-sentence tickets
new_tickets =  [
        "I want to cancel my order and get a refund because I never received it.",
        "Can you help me track my recent order? Also, I need to change my shipping address.",
        "I forgot my password and now my payment isn't going through. Help!",
        "Where can I see available delivery options? Also, I'd like to delete my account permanently.",
        "I tried to contact support, but no human agent responded. My payment also failed!",
]

ml_predictions = [predict_with_ml(ticket) for ticket in new_tickets]

# Print results
for i, (ticket, prediction) in enumerate(zip(new_tickets, ml_predictions)):
    print(f"\n=== Ticket {i+1} ===")
    print(f"Ticket Text: {ticket}")
    for model_name, result in prediction.items():
        print(f"\nModel: {model_name}")
        print(f"Predicted Category: {result['predicted_label']}")
        print(f"Probabilities: {result['probabilities']}")  # Prints full probability distribution

import pandas as pd
import numpy as np

# Prepare data for the table
table_data = []
for i, (ticket, prediction) in enumerate(zip(new_tickets, ml_predictions)):
    for model_name, result in prediction.items():
        # Extract probabilities
        if result['probabilities'] != "Not Available":
            probs = result['probabilities']

            # Handle nested list issue for SVM
            if isinstance(probs, list) and isinstance(probs[0], list):
                probs = probs[0]  # Extract first (and only) row for SVM(untill retrain svm with prob)

            probs = np.array(probs)  # Convert to NumPy array for safe indexing
            top_indices = np.argsort(probs)[-3:][::-1]  # Indices of top 3 predictions

            top_probs = [probs[j] for j in top_indices]  # Extract top probability values
            top_categories = label_encoder.inverse_transform(top_indices).tolist()  # Convert indices to category labels

            # Format predictions properly
            top_predictions_str = ', '.join([
                f"{top_categories[k]} ({top_probs[k]:.2f})" for k in range(len(top_categories))
            ])

        else:
            top_predictions_str = "Not Available"

        # Add row to table data
        table_data.append([i + 1, model_name, result['predicted_label'], top_predictions_str])

# Create pandas DataFrame
table_df = pd.DataFrame(table_data, columns=['Ticket #', 'Model', 'Predicted Category', 'Top Predictions (Category & Probability)'])

# Display the table
print(table_df)

# Save to CSV
table_df.to_csv('prediction_table.csv', index=False)

import tensorflow as tf
import pickle
import numpy as np
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load Tokenizer & Label Encoder
with open("/content/drive/MyDrive/models2/tokenizer.pkl", "rb") as handle:
    tokenizer = pickle.load(handle)

with open("/content/drive/MyDrive/models2/label_encoder.pkl", "rb") as handle:
    label_encoder = pickle.load(handle)

# Load Trained Model
lstm_model = tf.keras.models.load_model("/content/drive/MyDrive/models2/lstm_model.h5")

print("‚úÖ LSTM Model, tokenizer, and label encoder loaded successfully!")

# Function to Predict with LSTM and Extract Last-Layer Probabilities
def predict_with_lstm(model, text):
    seq = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=100)
    probabilities = model.predict(seq)[0]  # Extract softmax probabilities

    pred_index = np.argmax(probabilities)  # Get index of highest probability
    pred_label = label_encoder.inverse_transform([pred_index])[0]  # Convert to class label

    # Sort probabilities in descending order and extract top 3 classes
    top_indices = np.argsort(probabilities)[-3:][::-1]
    top_categories = label_encoder.inverse_transform(top_indices)  # Convert to class names
    top_probs = probabilities[top_indices]  # Extract corresponding probabilities

    # Format as dictionary
    result = {
        "Predicted Label": pred_label,
        "Probabilities": dict(zip(top_categories, top_probs))
    }
    return result

# Example Predictions for Multiple Tickets
new_tickets =  [
        "I want to cancel my order and get a refund because I never received it.",
        "Can you help me track my recent order? Also, I need to change my shipping address.",
        "I forgot my password and now my payment isn't going through. Help!",
        "Where can I see available delivery options? Also, I'd like to delete my account permanently.",
        "I tried to contact support, but no human agent responded. My payment also failed!",
]

# Get predictions
lstm_predictions = [predict_with_lstm(lstm_model, ticket) for ticket in new_tickets]

# Print Results
for i, (ticket, prediction) in enumerate(zip(new_tickets, lstm_predictions), 1):
    print(f"=== Ticket {i} ===")
    print(f"Ticket Text: {ticket}\n")
    print(f"Predicted Category: {prediction['Predicted Label']}")
    print("Top Predictions:")
    for category, prob in prediction["Probabilities"].items():
        print(f"- {category}: {prob:.4f}")
    print("\n" + "="*50 + "\n")

import pandas as pd
import joblib
import numpy as np
import tensorflow as tf
import pickle
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load Tokenizer & Label Encoder
with open("/content/drive/MyDrive/models2/tokenizer.pkl", "rb") as handle:
    tokenizer = pickle.load(handle)

with open("/content/drive/MyDrive/models2/label_encoder.pkl", "rb") as handle:
    label_encoder = pickle.load(handle)

# Load Trained Model
lstm_model = tf.keras.models.load_model("/content/drive/MyDrive/models2/lstm_model.h5")

def predict_with_lstm(model, text):
    seq = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=100)
    probabilities = model.predict(seq)[0]  # Extract softmax probabilities

    pred_index = np.argmax(probabilities)  # Get index of highest probability
    pred_label = label_encoder.inverse_transform([pred_index])[0]  # Convert to class label

    # Sort probabilities in descending order and extract top 3 classes
    top_indices = np.argsort(probabilities)[-3:][::-1]
    top_categories = label_encoder.inverse_transform(top_indices)  # Convert to class names
    top_probs = probabilities[top_indices]  # Extract corresponding probabilities

    # Format as dictionary
    result = {
        "Predicted Label": pred_label,
        "Probabilities": dict(zip(top_categories, top_probs))
    }
    return result


# Get predictions for LSTM
lstm_predictions = [predict_with_lstm(lstm_model, ticket) for ticket in new_tickets]

# Prepare data for the table
table_data = []
for i, (ticket, prediction) in enumerate(zip(new_tickets, ml_predictions)):
    for model_name, result in prediction.items():
        if result['probabilities'] != "Not Available":
            probs = result['probabilities']

            # Handle nested list issue for SVM
            if isinstance(probs, list) and isinstance(probs[0], list):
                probs = probs[0]  # Extract first (and only) row for SVM(before retrain with prob)

            probs = np.array(probs)  # Convert to NumPy array for safe indexing
            top_indices = np.argsort(probs)[-3:][::-1]  # Indices of top 3 predictions

            top_probs = [probs[j] for j in top_indices]  # Extract top probability values
            top_categories = label_encoder.inverse_transform(top_indices).tolist()  # Convert indices to category labels

            # Format predictions properly
            top_predictions_str = ', '.join([
                f"{top_categories[k]} ({top_probs[k]:.2f})" for k in range(len(top_categories))
            ])

        else:
            top_predictions_str = "Not Available"

        table_data.append([i + 1, ticket, model_name, result['predicted_label'], top_predictions_str])

    # Add LSTM prediction for the current ticket as the next row
    lstm_predicted_label = lstm_predictions[i]['Predicted Label']
    lstm_top_predictions_str = ', '.join([f"{cat} ({prob:.2f})" for cat, prob in lstm_predictions[i]['Probabilities'].items()])
    table_data.append([i + 1, ticket, 'LSTM', lstm_predicted_label, lstm_top_predictions_str])

# Create pandas DataFrame
table_df = pd.DataFrame(table_data, columns=['Ticket #', 'Ticket', 'Model', 'Predicted Category', 'Top Predictions (Category & Probability)'])

# Print results
print(table_df)

# Save to CSV
table_df.to_csv('merged_prediction_table_with_lstm.csv', index=False)

from transformers import BertTokenizer, TFBertForSequenceClassification
import numpy as np
import tensorflow as tf
import pickle

# Load Tokenizer & Model
tokenizer_bert = BertTokenizer.from_pretrained("/content/drive/MyDrive/models2/bert_tokenizer")
bert_model = TFBertForSequenceClassification.from_pretrained("/content/drive/MyDrive/models2/bert_model")

# Load Label Encoder
with open("/content/drive/MyDrive/models2/label_encoder.pkl", "rb") as handle:
    label_encoder = pickle.load(handle)

print("‚úÖ BERT Model, tokenizer, and label encoder loaded successfully!")

# Function to Predict with BERT and Extract Probabilities
def predict_with_bert(text):
    inputs = tokenizer_bert([text], padding=True, truncation=True, max_length=100, return_tensors="tf")
    logits = bert_model(inputs["input_ids"]).logits  # Get raw logits

    probabilities = tf.nn.softmax(logits, axis=1).numpy()[0]  # Convert logits to probabilities
    pred_index = np.argmax(probabilities)  # Get index of highest probability
    pred_label = label_encoder.inverse_transform([pred_index])[0]  # Convert to class label

    # Sort probabilities in descending order and extract top 3 classes
    top_indices = np.argsort(probabilities)[-3:][::-1]
    top_categories = label_encoder.inverse_transform(top_indices)  # Convert to class names
    top_probs = probabilities[top_indices]  # Extract corresponding probabilities

    # Format as dictionary
    result = {
        "Predicted Label": pred_label,
        "Probabilities": dict(zip(top_categories, top_probs))
    }
    return result

# Example Predictions for Multiple Tickets
new_tickets =  [
        "I want to cancel my order and get a refund because I never received it.",
        "Can you help me track my recent order? Also, I need to change my shipping address.",
        "I forgot my password and now my payment isn't going through. Help!",
        "Where can I see available delivery options? Also, I'd like to delete my account permanently.",
        "I tried to contact support, but no human agent responded. My payment also failed!",
]

# Get predictions
bert_predictions = [predict_with_bert(ticket) for ticket in new_tickets]

# Print Results
for i, (ticket, prediction) in enumerate(zip(new_tickets, bert_predictions), 1):
    print(f"=== Ticket {i} ===")
    print(f"Ticket Text: {ticket}\n")
    print(f"Predicted Category: {prediction['Predicted Label']}")
    print("Top Predictions:")
    for category, prob in prediction["Probabilities"].items():
        print(f"- {category}: {prob:.4f}")
    print("\n" + "="*50 + "\n")

import pandas as pd
import joblib
import numpy as np
import tensorflow as tf
import pickle
from tensorflow.keras.preprocessing.sequence import pad_sequences
from transformers import BertTokenizer, TFBertForSequenceClassification



# Load Tokenizer & Model
tokenizer_bert = BertTokenizer.from_pretrained("/content/drive/MyDrive/models2/bert_tokenizer_10")
bert_model = TFBertForSequenceClassification.from_pretrained("/content/drive/MyDrive/models2/bert_model_10")

# Load Label Encoder
with open("/content/drive/MyDrive/models2/label_encoder.pkl", "rb") as handle:
    label_encoder = pickle.load(handle)

print("‚úÖ BERT Model, tokenizer, and label encoder loaded successfully!")

# Load Tokenizer & Label Encoder
with open("/content/drive/MyDrive/models2/tokenizer.pkl", "rb") as handle:
    tokenizer = pickle.load(handle)

with open("/content/drive/MyDrive/models2/label_encoder.pkl", "rb") as handle:
    label_encoder = pickle.load(handle)

# Load Trained Model
lstm_model = tf.keras.models.load_model("/content/drive/MyDrive/models2/lstm_model.h5")

def predict_with_lstm(model, text):
    seq = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=100)
    probabilities_lstm = model.predict(seq)[0]  # Extract softmax probabilities

    pred_index_lstm= np.argmax(probabilities_lstm)  # Get index of highest probability
    pred_label_lstm = label_encoder.inverse_transform([pred_index_lstm])[0]  # Convert to class label

    # Sort probabilities in descending order and extract top 3 classes
    top_indices = np.argsort(probabilities_lstm)[-3:][::-1]
    top_categories = label_encoder.inverse_transform(top_indices)  # Convert to class names
    top_probs = probabilities_lstm[top_indices]  # Extract corresponding probabilities

    # Format as dictionary
    result_lstm = {
        "Predicted Label_lstm": pred_label_lstm,
        "probabilities_lstm": dict(zip(top_categories, top_probs))
    }
    return result_lstm
# Function to Predict with BERT and Extract Probabilities
def predict_with_bert(text):
    inputs = tokenizer_bert([text], padding=True, truncation=True, max_length=100, return_tensors="tf")
    logits = bert_model(inputs["input_ids"]).logits  # Get raw logits

    probabilities_bert = tf.nn.softmax(logits, axis=1).numpy()[0]  # Convert logits to probabilities
    pred_index = np.argmax(probabilities_bert)  # Get index of highest probability
    pred_label = label_encoder.inverse_transform([pred_index])[0]  # Convert to class label

    # Sort probabilities in descending order and extract top 3 classes
    top_indices = np.argsort(probabilities_bert)[-3:][::-1]
    top_categories = label_encoder.inverse_transform(top_indices)  # Convert to class names
    top_probs = probabilities_bert[top_indices]  # Extract corresponding probabilities

    # Format as dictionary
    result_bert = {
        "Predicted Label_bert": pred_label,
        "probabilities_bert": dict(zip(top_categories, top_probs))
    }
    return result_bert

# Get predictions for LSTM
lstm_predictions = [predict_with_lstm(lstm_model, ticket) for ticket in new_tickets]
bert_predictions = [predict_with_bert(ticket) for ticket in new_tickets]

# Prepare data for the table
table_data = []
for i, (ticket, prediction) in enumerate(zip(new_tickets, ml_predictions)):
    for model_name, result in prediction.items():
        if result['probabilities'] != "Not Available":
            probs = result['probabilities']

            # Handle nested list issue for SVM
            if isinstance(probs, list) and isinstance(probs[0], list):
                probs = probs[0]  # Extract first (and only) row for SVM(before retrain with probs)

            probs = np.array(probs)  # Convert to NumPy array for safe indexing
            top_indices = np.argsort(probs)[-3:][::-1]  # Indices of top 3 predictions

            top_probs = [probs[j] for j in top_indices]  # Extract top probability values
            top_categories = label_encoder.inverse_transform(top_indices).tolist()  # Convert indices to category labels

            # Format predictions properly
            top_predictions_str = ', '.join([
                f"{top_categories[k]} ({top_probs[k]:.2f})" for k in range(len(top_categories))
            ])

        else:
            top_predictions_str = "Not Available"

        table_data.append([i + 1, ticket, model_name, result['predicted_label'], top_predictions_str])

    # Add LSTM prediction for the current ticket as the next row
    lstm_predicted_label = lstm_predictions[i]['Predicted Label_lstm']
    lstm_top_predictions_str = ', '.join([f"{cat} ({prob:.2f})" for cat, prob in lstm_predictions[i]['probabilities_lstm'].items()])
    table_data.append([i + 1, ticket, 'LSTM', lstm_predicted_label, lstm_top_predictions_str])
    # Add BERT prediction to the table
    bert_predicted_label = bert_predictions[i]['Predicted Label_bert'] # Access bert_predictions using the index 'i'
    bert_top_predictions_str = ', '.join([f"{cat} ({prob:.2f})" for cat, prob in bert_predictions[i]['probabilities_bert'].items()])  # Access bert_predictions
    table_data.append([i + 1, ticket, 'BERT', bert_predicted_label, bert_top_predictions_str]) # Append to table_data

# Create pandas DataFrame
table_df = pd.DataFrame(table_data, columns=['Ticket #', 'Ticket', 'Model', 'Predicted Category', 'Top Predictions (Category & Probability)'])

# Print results
print(table_df)

# Save to CSV
table_df.to_csv('merged_prediction_table_all.csv', index=False)

import pandas as pd

# Assuming your DataFrame is named 'table_df'
table_df = pd.read_csv('merged_prediction_table_all.csv')

# Define the correct categories
correct_categories = [
    ["cancel_order", "get_refund"],
    ["track_order", "change_shipping_address"],
    ["account_recover_password", "payment_issue"],
    ["delivery_options", "delete_account"],
    ["contact_human_agent", "payment_issue"]
]

# Add 'Correct Categories' column
table_df['Correct Categories'] = ''  # Initialize the column

# Assign correct categories based on Ticket #
for i in range(len(correct_categories)):
    table_df.loc[table_df['Ticket #'] == i + 1, 'Correct Categories'] = str(correct_categories[i])

# Display the updated DataFrame
print(table_df)

# Save the updated DataFrame
table_df.to_csv('merged_prediction_table_all_with_correct.csv', index=False)

import pandas as pd

# Assuming your DataFrame is named 'table_df'
table_df = pd.read_csv('merged_prediction_table_all_with_correct.csv')

def test_function(row):
    """
    Checks if categories in 'Correct Categories' are in 'Top Predictions'.
    Returns "Correct" with bracket info (top 2 or 3) or 0.
    """
    correct_categories = eval(row['Correct Categories'])  # Convert string to list
    top_predictions_str = row['Top Predictions (Category & Probability)']

    if top_predictions_str == "Not Available":
        return 0  # Handle cases where probabilities aren't available untill retrain (retrain done)

    # Extract top categories from prediction string
    top_predictions = [pred.split(' (')[0] for pred in top_predictions_str.split(', ')]

    # Check if all correct categories are in top predictions
    all_correct_in_top = all(cat in top_predictions for cat in correct_categories)

    if all_correct_in_top:
        # Check if all correct categories are in top 2
        all_correct_in_top2 = all(cat in top_predictions[:2] for cat in correct_categories)
        if all_correct_in_top2:
            return "Correct (in top 2)"
        else:
            return "Correct (in top 3)"  # If not in top 2, but in top 3
    else:
        return 0  # If not all correct categories are in top predictions

# Apply the test function and create a new column
table_df['Test Result'] = table_df.apply(test_function, axis=1)

# Display the updated DataFrame
print(table_df)

# Save the updated DataFrame
table_df.to_csv('merged_prediction_table_all_with_correct_and_test.csv', index=False)

"""#multiclass output"""

import joblib
import numpy as np

# Load ML Models
ml_models = {
    "Logistic Regression": joblib.load("/content/drive/MyDrive/models4/Logistic Regression.pkl"),
    "SVM": joblib.load("/content/drive/MyDrive/models4/SVM.pkl"),
    "SGD": joblib.load("/content/drive/MyDrive/models4/SGD.pkl"),
    "Random Forest": joblib.load("/content/drive/MyDrive/models2/Random Forest.pkl"),
    "Na√Øve Bayes": joblib.load("/content/drive/MyDrive/models4/Na√Øve Bayes.pkl")
}

# Load TF-IDF Vectorizer and Label Encoder
tfidf_vectorizer = joblib.load("/content/drive/MyDrive/models4/tfidf_vectorizer.pkl")
label_encoder = joblib.load("/content/drive/MyDrive/models2/label_encoder.pkl")

def apply_dynamic_thresholding(probabilities, categories):
    """
    Cluster-based dynamic thresholding with top-4 rule.
    """
    sorted_indices = np.argsort(probabilities)[::-1]
    sorted_probs = np.array(probabilities)[sorted_indices]
    sorted_cats = [categories[i] for i in sorted_indices]

    main_category = sorted_cats[0]
    additional = []
    high_conf_indices = [0]

    # Rule 1: High-confidence chain (‚â•0.5, difference ‚â§0.2)
    for i in range(1, len(sorted_probs)):
        if sorted_probs[i] >= 0.5 and (sorted_probs[i-1] - sorted_probs[i]) <= 0.2:
            high_conf_indices.append(i)
        else:
            break

    # Rule 2: Low-confidence clusters (<0.5, within-cluster difference ‚â§0.1)
    low_conf_probs = [(prob, idx) for idx, prob in enumerate(sorted_probs)
                     if (prob < 0.5 and prob > 0.1 and idx not in high_conf_indices)]
    clusters = []
    current_cluster = []
    for prob, idx in low_conf_probs:
        if not current_cluster:
            current_cluster.append((prob, idx))
        else:
            if current_cluster[-1][0] - prob <= 0.1:
                current_cluster.append((prob, idx))
            else:
                clusters.append(current_cluster)
                current_cluster = [(prob, idx)]
    if current_cluster:
        clusters.append(current_cluster)

    clusters.sort(key=lambda x: len(x), reverse=True)
    selected_low_conf = []
    for cluster in clusters:
        selected_low_conf.extend([idx for (prob, idx) in cluster])
        if len(selected_low_conf) >= 4 - len(high_conf_indices):
            break

    # Combine results (max 4 categories)
    all_selected = high_conf_indices + selected_low_conf[:4 - len(high_conf_indices)]
    additional = [f"{sorted_cats[idx]} ({sorted_probs[idx]:.2f})" for idx in all_selected if idx != 0]

    return main_category, additional

def predict_with_ml(text):
    text_tfidf = tfidf_vectorizer.transform([text])
    predictions = {}

    for name, model in ml_models.items():
        try:
            # Handle SGD (use decision function if no predict_proba)
            if hasattr(model, "predict_proba"):
                probs = model.predict_proba(text_tfidf)[0]
            else:
                scores = model.decision_function(text_tfidf)[0]
                probs = 1 / (1 + np.exp(-scores))  # Convert to pseudo-probabilities for sgd before retrain with log_loss
        except AttributeError:
            continue

        main_category, additional = apply_dynamic_thresholding(probs, label_encoder.classes_)

        if additional:
            formatted_output = f"The main category is '{main_category}'. Also consider: {', '.join(additional)}"
        else:
            formatted_output = f"The main category is '{main_category}'."

        predictions[name] = formatted_output

    return predictions

# Test on long multi-sentence tickets
new_tickets = [
    "I want to cancel my order and get a refund because I never received it.",
    "Can you help me track my recent order? Also, I need to change my shipping address.",
    "I forgot my password and now my payment isn't going through. Help!",
    "Where can I see available delivery options? Also, I'd like to delete my account permanently.",
    "I tried to contact support, but no human agent responded. My payment also failed!"
]

ml_predictions = [predict_with_ml(ticket) for ticket in new_tickets]

# Print results
for i, (ticket, prediction) in enumerate(zip(new_tickets, ml_predictions)):
    print(f"\n=== Ticket {i+1} ===")
    print(f"Ticket Text: {ticket}")
    for model_name, result in prediction.items():
        print(f"\nModel: {model_name}")
        print(f"Prediction: {result}")

import tensorflow as tf
from transformers import BertTokenizer, TFBertForSequenceClassification
import pickle
import numpy as np

# Load LSTM Components
with open("/content/drive/MyDrive/models2/tokenizer.pkl", "rb") as handle:
    lstm_tokenizer = pickle.load(handle)

lstm_model = tf.keras.models.load_model("/content/drive/MyDrive/models2/lstm_model.h5")
max_length = 100

# Load BERT Components
tokenizer_bert = BertTokenizer.from_pretrained("/content/drive/MyDrive/models2/bert_tokenizer_10")
bert_model = TFBertForSequenceClassification.from_pretrained("/content/drive/MyDrive/models2/bert_model_10")

# Load Label Encoder
with open("/content/drive/MyDrive/models2/label_encoder.pkl", "rb") as handle:
    label_encoder = pickle.load(handle)

def apply_dynamic_thresholding(probabilities):
    sorted_indices = np.argsort(probabilities)[::-1]
    sorted_probs = np.array(probabilities)[sorted_indices]
    sorted_cats = label_encoder.inverse_transform(sorted_indices)

    main_category = sorted_cats[0]
    additional = []
    high_conf_indices = [0]

    # Rule 1: High-confidence chain
    for i in range(1, len(sorted_probs)):
        if sorted_probs[i] >= 0.5 and (sorted_probs[i-1] - sorted_probs[i]) <= 0.2:
            high_conf_indices.append(i)
        else:
            break

    # Rule 2: Low-confidence clusters
    low_conf_probs = [(prob, idx) for idx, prob in enumerate(sorted_probs)
                     if (prob < 0.5 and prob > 0.1 and idx not in high_conf_indices)]
    clusters = []
    current_cluster = []
    for prob, idx in low_conf_probs:
        if not current_cluster:
            current_cluster.append((prob, idx))
        else:
            if current_cluster[-1][0] - prob <= 0.1:
                current_cluster.append((prob, idx))
            else:
                clusters.append(current_cluster)
                current_cluster = [(prob, idx)]
    if current_cluster:
        clusters.append(current_cluster)

    clusters.sort(key=lambda x: len(x), reverse=True)
    selected_low_conf = []
    for cluster in clusters:
        selected_low_conf.extend([idx for (prob, idx) in cluster])
        if len(selected_low_conf) >= 4 - len(high_conf_indices):
            break

    # Combine results
    all_selected = high_conf_indices + selected_low_conf[:4 - len(high_conf_indices)]
    additional = [f"{sorted_cats[idx]} ({sorted_probs[idx]:.2f})" for idx in all_selected if idx != 0]

    if additional:
        return f"The main category is '{main_category}'. Also consider: {', '.join(additional)}"
    else:
        return f"The main category is '{main_category}'."

def predict_with_dl(text):
    predictions = {}

    # LSTM Prediction (Fixed)
    sequence = lstm_tokenizer.texts_to_sequences([text])
    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=max_length)
    lstm_probs = lstm_model.predict(padded_sequence, verbose=0)[0]
    predictions["LSTM"] = apply_dynamic_thresholding(lstm_probs)

    # BERT Prediction
    inputs = tokenizer_bert(text, return_tensors="tf", padding=True, truncation=True, max_length=512)
    bert_output = bert_model(**inputs)
    bert_probs = tf.nn.softmax(bert_output.logits, axis=-1).numpy()[0]
    predictions["BERT"] = apply_dynamic_thresholding(bert_probs)

    return predictions


# Test on long multi-sentence tickets
new_tickets = [
    "I want to cancel my order and get a refund because I never received it.",
    "Can you help me track my recent order? Also, I need to change my shipping address.",
    "I forgot my password and now my payment isn't going through. Help!",
    "Where can I see available delivery options? Also, I'd like to delete my account permanently.",
    "I tried to contact support, but no human agent responded. My payment also failed!"
]

dl_predictions = [predict_with_dl(ticket) for ticket in new_tickets]

# Print results
for i, (ticket, prediction) in enumerate(zip(new_tickets, dl_predictions)):
    print(f"\n=== Ticket {i+1} ===")
    print(f"Ticket Text: {ticket}")
    for model_name, result in prediction.items():
        print(f"\nModel: {model_name}")
        print(f"Prediction: {result}")

"""# compression table"""

import joblib
import numpy as np
import pandas as pd

# Load ML Models
ml_models = {
    "Logistic Regression": joblib.load("/content/drive/MyDrive/models4/Logistic Regression.pkl"),
    "SVM": joblib.load("/content/drive/MyDrive/models4/SVM.pkl"),
    "SGD": joblib.load("/content/drive/MyDrive/models4/SGD.pkl"),
    "Random Forest": joblib.load("/content/drive/MyDrive/models2/Random Forest.pkl"),
    "Na√Øve Bayes": joblib.load("/content/drive/MyDrive/models4/Na√Øve Bayes.pkl")
}

# Load TF-IDF Vectorizer and Label Encoder
tfidf_vectorizer = joblib.load("/content/drive/MyDrive/models4/tfidf_vectorizer.pkl")
label_encoder = joblib.load("/content/drive/MyDrive/models2/label_encoder.pkl")

def apply_dynamic_thresholding(probabilities, categories):
    """
    Determines the main category and additional relevant categories using cluster-based dynamic thresholding.
    """
    sorted_indices = np.argsort(probabilities)[::-1]
    sorted_probs = np.array(probabilities)[sorted_indices]
    sorted_cats = [categories[i] for i in sorted_indices]

    main_category = sorted_cats[0]
    additional = []
    high_conf_indices = [0]

    # Rule 1: High-confidence chain
    for i in range(1, len(sorted_probs)):
        if sorted_probs[i] >= 0.5 and (sorted_probs[i-1] - sorted_probs[i]) <= 0.2:
            high_conf_indices.append(i)
        else:
            break

    # Rule 2: Low-confidence clusters
    low_conf_probs = [(prob, idx) for idx, prob in enumerate(sorted_probs)
                     if (prob < 0.5 and prob > 0.1 and idx not in high_conf_indices)]
    clusters = []
    current_cluster = []
    for prob, idx in low_conf_probs:
        if not current_cluster:
            current_cluster.append((prob, idx))
        else:
            if current_cluster[-1][0] - prob <= 0.1:
                current_cluster.append((prob, idx))
            else:
                clusters.append(current_cluster)
                current_cluster = [(prob, idx)]
    if current_cluster:
        clusters.append(current_cluster)

    clusters.sort(key=lambda x: len(x), reverse=True)
    selected_low_conf = []
    for cluster in clusters:
        selected_low_conf.extend([idx for (prob, idx) in cluster])
        if len(selected_low_conf) >= 4 - len(high_conf_indices):
            break

    # Combine results (max 4 categories)
    all_selected = high_conf_indices + selected_low_conf[:4 - len(high_conf_indices)]
    additional_categories = [sorted_cats[idx] for idx in all_selected if idx != 0]

    return main_category, additional_categories

def predict_with_ml(text):
    text_tfidf = tfidf_vectorizer.transform([text])
    predictions = {}

    for name, model in ml_models.items():
        try:
            if hasattr(model, "predict_proba"):
                probs = model.predict_proba(text_tfidf)[0]
            elif hasattr(model, "decision_function"):
                scores = model.decision_function(text_tfidf)[0]
                probs = 1 / (1 + np.exp(-scores))  # Sigmoid for SGD
            else:
                probs = None
        except Exception as e:
            print(f"Error with {name}: {str(e)}")
            probs = None

        if probs is not None:
            main_category, additional_categories = apply_dynamic_thresholding(probs, label_encoder.classes_)
        else:
            main_category, additional_categories = "Unknown", []

        predictions[name] = {
            "main": main_category,
            "additional": additional_categories
        }

    return predictions

# Test Cases
new_tickets = [
    "I want to cancel my order and get a refund because I never received it.",
    "Can you help me track my recent order? Also, I need to change my shipping address.",
    "I forgot my password and now my payment isn't going through. Help!",
    "Where can I see available delivery options? Also, I'd like to delete my account permanently.",
    "I tried to contact support, but no human agent responded. My payment also failed!"
]

correct_categories = [
    ["cancel_order", "get_refund"],
    ["track_order", "change_shipping_address"],
    ["account_recover_password", "payment_issue"],
    ["delivery_options", "delete_account"],
    ["contact_human_agent", "payment_issue"]
]

# Evaluation Metrics Storage
accuracy_data = []

for ticket_idx, (ticket, correct_labels) in enumerate(zip(new_tickets, correct_categories)):
    predictions = predict_with_ml(ticket)

    for model_name, preds in predictions.items():
        main_pred = preds["main"]
        additional_preds = preds["additional"]

        # Calculate Accuracies
        main_accuracy = 1 if main_pred in correct_labels else 0
        all_preds = set([main_pred] + additional_preds)
        multi_accuracy = 1 if all_preds == set(correct_labels) else 0

        accuracy_data.append({
            "Ticket #": ticket_idx + 1,
            "Model": model_name,
            "Main Accuracy": main_accuracy,
            "Multi Accuracy": multi_accuracy
        })

# Calculate Final Accuracy Scores
df = pd.DataFrame(accuracy_data)
accuracy_results = df.groupby("Model").agg(
    Main_Accuracy=("Main Accuracy", "mean"),
    Multi_Label_Accuracy=("Multi Accuracy", "mean")
).reset_index()

print("\n=== Model Accuracy Summary ===")
print(accuracy_results.round(2))

# Save Detailed Results
df.to_csv("detailed_accuracy_results.csv", index=False)

# Generate Detailed Predictions and Save to CSV
detailed_results = []

for ticket_idx, (ticket, correct_labels) in enumerate(zip(new_tickets, correct_categories)):
    predictions = predict_with_ml(ticket)

    for model_name, preds in predictions.items():
        main_pred = preds["main"]
        additional_preds = preds["additional"]

        # Calculate Accuracies
        main_accuracy = "correct" if main_pred in correct_labels else "wrong"
        all_preds = set([main_pred] + additional_preds)
        multi_accuracy = "correct" if all_preds == set(correct_labels) else "wrong"

        detailed_results.append({
            "Ticket#": ticket_idx + 1,
            "Ticket": ticket,
            "Model": model_name,
            "Correct Categories": ", ".join(correct_labels),
            "Main Category": main_pred,
            "Other Considered Categories": ", ".join(additional_preds),
            "Main Accuracy": main_accuracy,
            "Multi Accuracy": multi_accuracy
        })

# Create and Save Detailed DataFrame
detailed_df = pd.DataFrame(detailed_results, columns=[
    "Ticket#", "Ticket", "Model", "Correct Categories",
    "Main Category", "Other Considered Categories",
    "Main Accuracy", "Multi Accuracy"
])

# Save to CSV
detailed_df.to_csv("detailed_accuracy_report.csv", index=False)

# Print sample
print("\n=== Sample Detailed Results ===")
print(detailed_df.head().to_markdown(index=False))

# Calculate and Print Summary Statistics
summary_df = detailed_df.groupby('Model').agg(
    Main_Accuracy=('Main Accuracy', lambda x: (x == 'correct').mean()),
    Multi_Accuracy=('Multi Accuracy', lambda x: (x == 'correct').mean())
).reset_index()

print("\n=== Accuracy Summary ===")
print(summary_df.round(2).to_markdown(index=False))

# ... (keep previous imports and model loading code)

# Modified Evaluation Section
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.metrics import f1_score

# Initialize F1 calculation tools
all_categories = label_encoder.classes_
mlb = MultiLabelBinarizer(classes=all_categories)
mlb.fit([all_categories])  # Prepare encoder for all possible categories

# Store predictions for F1 calculation
model_predictions = {model: {'true': [], 'pred': []} for model in ml_models.keys()}

# Generate Detailed Predictions
detailed_results = []
for ticket_idx, (ticket, correct_labels) in enumerate(zip(new_tickets, correct_categories)):
    predictions = predict_with_ml(ticket)

    for model_name, preds in predictions.items():
        main_pred = preds["main"]
        additional_preds = preds["additional"]
        all_preds = set([main_pred] + additional_preds)

        # Store for F1 calculation
        model_predictions[model_name]['true'].append(set(correct_labels))
        model_predictions[model_name]['pred'].append(all_preds)

        # Format for human-readable report
        main_accuracy = "correct" if main_pred in correct_labels else "wrong"

        detailed_results.append({
            "Ticket#": ticket_idx + 1,
            "Ticket": ticket,
            "Model": model_name,
            "Correct Categories": ", ".join(correct_labels),
            "Main Category": main_pred,
            "Other Considered Categories": ", ".join(additional_preds),
            "Main Accuracy": main_accuracy
        })

# Calculate F1 Scores
f1_results = []
for model in ml_models.keys():
    y_true = mlb.transform(model_predictions[model]['true'])
    y_pred = mlb.transform(model_predictions[model]['pred'])
    micro_f1 = f1_score(y_true, y_pred, average='micro')
    macro_f1 = f1_score(y_true, y_pred, average='macro')

    f1_results.append({
        "Model": model,
        "Micro F1": micro_f1,
        "Macro F1": macro_f1
    })

# Create Final Report
detailed_df = pd.DataFrame(detailed_results)
f1_df = pd.DataFrame(f1_results)

# Merge with existing accuracy data
summary_df = detailed_df.groupby('Model').agg(
    Main_Accuracy=('Main Accuracy', lambda x: (x == 'correct').mean())
).reset_index()

final_report = pd.merge(summary_df, f1_df, on='Model')

# Save and Display
detailed_df.to_csv("detailed_results.csv", index=False)
final_report.to_csv("model_performance_report.csv", index=False)

print("\n=== Final Performance Report ===")
print(final_report.round(2).to_markdown(index=False))

# Generate Detailed Predictions
detailed_results = []
for ticket_idx, (ticket, correct_labels) in enumerate(zip(new_tickets, correct_categories)):
    predictions = predict_with_ml(ticket)

    for model_name, preds in predictions.items():
        main_pred = preds["main"]
        additional_preds = preds["additional"]
        all_preds = [main_pred] + additional_preds

        # Calculate Metrics
        main_accuracy = 1 if main_pred in correct_labels else 0
        all_correct = 1 if set(correct_labels).issubset(set(all_preds)) else 0

        detailed_results.append({
            "Ticket#": ticket_idx + 1,
            "Ticket": ticket,
            "Model": model_name,
            "Correct Categories": correct_labels,  # Store as list instead of string
            "Main Category": main_pred,
            "Other Considered Categories": ", ".join(additional_preds),
            "Main Accuracy": main_accuracy,
            "Any Correct Accuracy": all_correct  # Changed to ALL correct
        })

# Calculate Metrics
performance_data = []
for model in ml_models.keys():
    model_df = pd.DataFrame(detailed_results)
    model_df = model_df[model_df['Model'] == model]

    main_acc = model_df['Main Accuracy'].mean()
    all_acc = model_df['Any Correct Accuracy'].mean()

    # Calculate Micro F1 (Modified)
    y_true = mlb.transform(model_df['Correct Categories'].tolist()) # Directly use the list
    y_pred = mlb.transform([row['Main Category'].split(', ') + row['Other Considered Categories'].split(', ')
                          for _, row in model_df.iterrows()])
    micro_f1 = f1_score(y_true, y_pred, average='micro', zero_division=0)

    performance_data.append({
        "Model": model,
        "Main Accuracy": main_acc,
        "All Correct Accuracy": all_acc,  # Renamed for clarity
        "Micro F1": micro_f1
    })
# Create Final Report
detailed_df = pd.DataFrame(detailed_results)
performance_data_df = pd.DataFrame(performance_data)

# Merge with existing accuracy data
summary_df = detailed_df.groupby('Model').agg(
    Main_Accuracy=('Main Accuracy', lambda x: (x == 'correct').mean())
).reset_index()

final_report = pd.merge(summary_df, performance_data_df, on='Model')

# Save and Display
detailed_df.to_csv("detailed_results.csv", index=False)

# Final Report
print("\n=== Final Performance Report ===")
print(pd.DataFrame(performance_data).round(2).to_markdown(index=False))

import joblib
import numpy as np
import pandas as pd
import tensorflow as tf
import pickle
from transformers import BertTokenizer, TFBertForSequenceClassification
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.metrics import f1_score
import logging

# ========== Load All Components ==========
def load_components():
    """Load all required models and components"""
    components = {}

    # Load BERT components

    logging.getLogger("transformers").setLevel(logging.ERROR)

    # Then load BERT

    components['bert_tokenizer'] = BertTokenizer.from_pretrained("/content/drive/MyDrive/models2/bert_tokenizer_10")
    components['bert_model'] = TFBertForSequenceClassification.from_pretrained(
    "/content/drive/MyDrive/models2/bert_model_10",
    ignore_mismatched_sizes=True ) # Add this parameter

    # Load LSTM components
    components['lstm_model'] = tf.keras.models.load_model("/content/drive/MyDrive/models2/lstm_model.h5")
    components['lstm_model'].compile_metrics = []  # Disable empty metric warnings
    with open("/content/drive/MyDrive/models2/tokenizer.pkl", "rb") as handle:
        components['lstm_tokenizer'] = pickle.load(handle)

    # Load shared components
    components['label_encoder'] = joblib.load("/content/drive/MyDrive/models2/label_encoder.pkl")
    components['tfidf_vectorizer'] = joblib.load("/content/drive/MyDrive/models4/tfidf_vectorizer.pkl")

    # Load ML models
    ml_models = {
        "Logistic Regression": joblib.load("/content/drive/MyDrive/models4/Logistic Regression.pkl"),
        "SVM": joblib.load("/content/drive/MyDrive/models4/SVM.pkl"),
        "SGD": joblib.load("/content/drive/MyDrive/models4/SGD.pkl"),
        "Random Forest": joblib.load("/content/drive/MyDrive/models2/Random Forest.pkl"),
        "Na√Øve Bayes": joblib.load("/content/drive/MyDrive/models4/Na√Øve Bayes.pkl")
    }
    components.update(ml_models)

    return components

# ========== Dynamic Thresholding Function ==========
def apply_dynamic_thresholding(probabilities, label_encoder):
    """Cluster-based dynamic thresholding with label mapping"""
    categories = label_encoder.classes_
    sorted_indices = np.argsort(probabilities)[::-1]
    sorted_probs = np.array(probabilities)[sorted_indices]
    sorted_cats = [categories[i] for i in sorted_indices]

    main_category = sorted_cats[0]
    additional = []
    high_conf_indices = [0]

    # Rule 1: High-confidence chain
    for i in range(1, len(sorted_probs)):
        if sorted_probs[i] >= 0.5 and (sorted_probs[i-1] - sorted_probs[i]) <= 0.2:
            high_conf_indices.append(i)
        else:
            break

    # Rule 2: Low-confidence clusters
    low_conf_probs = [(prob, idx) for idx, prob in enumerate(sorted_probs)
                     if (prob < 0.5 and prob > 0.1 and idx not in high_conf_indices)]

    clusters = []
    current_cluster = []
    for prob, idx in low_conf_probs:
        if not current_cluster:
            current_cluster.append((prob, idx))
        else:
            if current_cluster[-1][0] - prob <= 0.1:
                current_cluster.append((prob, idx))
            else:
                clusters.append(current_cluster)
                current_cluster = [(prob, idx)]
    if current_cluster:
        clusters.append(current_cluster)

    clusters.sort(key=lambda x: len(x), reverse=True)
    selected_low_conf = []
    for cluster in clusters:
        selected_low_conf.extend([idx for (prob, idx) in cluster])
        if len(selected_low_conf) >= 4 - len(high_conf_indices):
            break

    # Combine results (max 4 categories)
    all_selected = high_conf_indices + selected_low_conf[:4 - len(high_conf_indices)]
    additional_categories = [sorted_cats[idx] for idx in all_selected if idx != 0]

    return main_category, additional_categories

# ========== Prediction Functions ==========
def predict_ml(text, model, components):
    """Predict with ML models"""
    text_tfidf = components['tfidf_vectorizer'].transform([text])
    le = components['label_encoder']

    if hasattr(model, "predict_proba"):
        probs = model.predict_proba(text_tfidf)[0]
    else:
        scores = model.decision_function(text_tfidf)[0]
        probs = 1 / (1 + np.exp(-scores))  # Sigmoid scaling

    return apply_dynamic_thresholding(probs, le)  # Pass label encoder

def predict_dl(text, model_type, components):
    """Predict with DL models"""
    le = components['label_encoder']

    if model_type == "LSTM":
        sequence = components['lstm_tokenizer'].texts_to_sequences([text])
        padded = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=200)
        probs = components['lstm_model'].predict(padded, verbose=0)[0]
    elif model_type == "BERT":
        inputs = components['bert_tokenizer'](text, return_tensors="tf",
                                            padding=True, truncation=True,
                                            max_length=512)
        outputs = components['bert_model'](**inputs)
        probs = tf.nn.softmax(outputs.logits, axis=-1).numpy()[0]

    return apply_dynamic_thresholding(probs, le)  # Pass label encoder

# ========== Evaluation Framework ==========
def evaluate_all_models(texts, correct_labels):
    """Evaluate all models on given texts"""
    components = load_components()
    results = []

    for idx, (text, true_labels) in enumerate(zip(texts, correct_labels)):
        # ML Models
        for ml_name in ["Logistic Regression", "SVM", "SGD", "Random Forest", "Na√Øve Bayes"]:
            main, additional = predict_ml(text, components[ml_name], components)
            results.append(record_result(idx+1, text, ml_name, true_labels, main, additional))

        # DL Models
        for dl_name in ["LSTM", "BERT"]:
            main, additional = predict_dl(text, dl_name, components)
            results.append(record_result(idx+1, text, dl_name, true_labels, main, additional))

    return pd.DataFrame(results)

def record_result(ticket_id, text, model_name, true_labels, main_pred, additional_preds):
    """Create standardized result entry"""
    all_preds = [main_pred] + additional_preds
    return {
        "Ticket#": ticket_id,
        "Ticket": text,
        "Model": model_name,
        "Correct": true_labels,
        "Main": main_pred,
        "Additional": additional_preds,
        "MainAcc": int(main_pred in true_labels),
        "MulticlassAccuracy": int(set(all_preds) == set(true_labels)) ,
        "AllCorrect": int(set(true_labels).issubset(set(all_preds)))
    }

# ========== Metrics Calculation ==========
def calculate_metrics(results_df, label_encoder):
    """Calculate final performance metrics"""
    # Initialize and fit the MultiLabelBinarizer with ALL possible classes
    mlb = MultiLabelBinarizer()
    mlb.fit([label_encoder.classes_])  # Fit on all possible categories

    # Transform true and predicted labels
    y_true = mlb.transform(results_df['Correct'])
    y_pred = mlb.transform(
        results_df.apply(lambda x: [x['Main']] + x['Additional'], axis=1)
    )

    # Calculate metrics
    metrics = results_df.groupby('Model').agg(
        MainAccuracy=('MainAcc', 'mean'),
        MulticlassAccuracy=('MulticlassAccuracy', 'mean'),
        AllCorrectAccuracy=('AllCorrect', 'mean'),
    ).reset_index()

    # Add Micro F1
    metrics['MicroF1'] = [
        f1_score(y_true[results_df['Model'] == model],
        y_pred[results_df['Model'] == model],
        average='micro', zero_division=0
        )
        for model in metrics['Model']
    ]

    return metrics.round(3)

# ========== Execution (Fixed) ==========
if __name__ == "__main__":
    components = load_components()  # Load once here

    # Test data
    test_texts =  [
    "I want to cancel my order and get a refund because I never received it.",
    "Can you help me track my recent order? Also, I need to change my shipping address.",
    "I forgot my password and now my payment isn't going through. Help!",
    "Where can I see available delivery options? Also, I'd like to delete my account permanently.",
    "I tried to contact support, but no human agent responded. My payment also failed!"
]

    correct_labels = [
    ["cancel_order", "get_refund"],
    ["track_order", "change_shipping_address"],
    ["account_recover_password", "payment_issue"],
    ["delivery_options", "delete_account"],
    ["contact_human_agent", "payment_issue"]
]  # Corresponding correct labels

    # Run evaluation
    results_df = evaluate_all_models(test_texts, correct_labels)
    final_metrics = calculate_metrics(results_df, components['label_encoder'])

    # Save and display
    results_df.to_csv("full_results.csv", index=False)
    print("\n=== Final Metrics ===")
    print(final_metrics.to_markdown(index=False))

# Add this dictionary mapping test accuracies
TEST_ACCURACIES = {
    "BERT": 0.99695555,
    "SVM": 0.9955,
    "SGD": 0.9896,
    "Logistic Regression": 0.9933,
    "Na√Øve Bayes": 0.9907,
    "Random Forest": 0.988,
    "LSTM": 0.98437183
}

# Modify metrics calculation
def calculate_metrics(results_df, label_encoder):
    """Calculate final performance metrics"""
    # Initialize and fit the MultiLabelBinarizer with ALL possible classes
    mlb = MultiLabelBinarizer()
    mlb.fit([label_encoder.classes_])  # Fit on all possible categories

    # Transform true and predicted labels
    y_true = mlb.transform(results_df['Correct'])
    y_pred = mlb.transform(
        results_df.apply(lambda x: [x['Main']] + x['Additional'], axis=1)
    )

    metrics = results_df.groupby('Model').agg(
        MainAccuracy=('MainAcc', 'mean'),
        MulticlassAccuracy=('MulticlassAccuracy', 'mean'),
        MicroF1=('Model', lambda x: f1_score(y_true[x.index], y_pred[x.index],
                                            average='micro', zero_division=0))
    ).reset_index()

    # Add test accuracy for dataset
    metrics['Test Accuracy_dataset'] = metrics['Model'].map(TEST_ACCURACIES)

    # Reorder columns
    return metrics[['Model', 'Test Accuracy_dataset', 'MainAccuracy',
                    'MulticlassAccuracy', 'MicroF1']].round(3)
# ========== Execution (Fixed) ==========
if __name__ == "__main__":
    components = load_components()  # Load once here

    # Test data
    test_texts =  [
    "I want to cancel my order and get a refund because I never received it.",
    "Can you help me track my recent order? Also, I need to change my shipping address.",
    "I forgot my password and now my payment isn't going through. Help!",
    "Where can I see available delivery options? Also, I'd like to delete my account permanently.",
    "I tried to contact support, but no human agent responded. My payment also failed!"
]

    correct_labels = [
    ["cancel_order", "get_refund"],
    ["track_order", "change_shipping_address"],
    ["account_recover_password", "payment_issue"],
    ["delivery_options", "delete_account"],
    ["contact_human_agent", "payment_issue"]
]  # Corresponding correct labels

    # Run evaluation
    results_df = evaluate_all_models(test_texts, correct_labels)
    final_metrics = calculate_metrics(results_df, components['label_encoder'])

    # Save and display

    print("\n=== Final Metrics ===")
    print(final_metrics.to_markdown(index=False))

import matplotlib.pyplot as plt
import pandas as pd

data = {
    "Model": ["BERT", "LSTM", "Logistic Regression", "Na√Øve Bayes", "Random Forest", "SGD", "SVM"],
    "Test Accuracy": [0.997, 0.984, 0.993, 0.991, 0.988, 0.99, 0.996],
    "Main Accuracy": [1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0],
    "Multiclass Accuracy": [0.0, 0.0, 0.4, 0.2, 0.4, 0.4, 0.2],
    "Micro F1": [0.667, 0.444, 0.778, 0.778, 0.75, 0.824, 0.778]
}

df = pd.DataFrame(data)
df.set_index("Model", inplace=True)

# Plot
ax = df.plot(kind="bar", figsize=(12, 6), width=0.8)
plt.title("Model Performance Comparison")
plt.ylabel("Score")
plt.xticks(rotation=45, ha='right')
plt.ylim(0, 1.2)
plt.legend(loc='upper left', bbox_to_anchor=(1, 1))

# Add accuracy values above each bar with adjustments for Test Accuracy
for i, p in enumerate(ax.patches):
    height = p.get_height()
    x = p.get_x() + p.get_width() / 2.
    y = height

    # Adjust y position for Test Accuracy annotations

    if i < len(df):  # Only apply to Test Accuracy bars
        y -= 0.03  # Lower the annotation (adjust value as needed)
    else:
        y += 0.03  # Raise the annotation (adjust value as needed)

    # Annotate with adjusted position
    ax.annotate(f"{height:.3f}", (x, y),
                ha='center', va='center',
                xytext=(0, 10),  # Adjust vertical offset here
                textcoords='offset points',
                fontsize=12)
plt.tight_layout()
plt.show()

import numpy as np

# Normalize data to 0-1 scale
normalized_df = (df - df.min()) / (df.max() - df.min())

# Create radar chart
categories = list(normalized_df.columns)
N = len(categories)
angles = np.linspace(0, 2 * np.pi, N, endpoint=False).tolist()

fig = plt.figure(figsize=(8, 8))
ax = fig.add_subplot(111, polar=True)

for model in normalized_df.index:
    values = normalized_df.loc[model].tolist()
    values += values[:1]  # Close the radar chart
    ax.plot(angles + angles[:1], values, label=model)

ax.set_xticks(angles)
ax.set_xticklabels(categories)
plt.title("Radar Chart of Model Performance (Normalized)",pad=30)
plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))
plt.show()

"""Best Overall (Multi-Label): **Random Forest**

Best Single-Label: **BERT**

Most Balanced: **Logistic Regression/SVM**

Avoid: **LSTM** (underperforms in all metrics)

#pipeline
"""

!pip install contractions
# Download 'wordnet' dataset
!pip install textblob  # Install the textblob package

import nltk # Import nltk

# Download necessary NLTK data
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('punkt_tab')  # Add this line to download the 'punkt_tab' resource
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

import re
import string
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import numpy as np
import joblib
import tensorflow as tf
from sklearn.pipeline import Pipeline
from transformers import BertTokenizer, TFBertForSequenceClassification
import contractions
import nltk # Import nltk
from nltk.stem import WordNetLemmatizer # Import WordNetLemmatizer
from textblob import TextBlob # Import TextBlob

def clean_text_advanced(text):
    # Expand contractions
    text = contractions.fix(text)

    # Lowercase
    text = text.lower()

    # Remove digits and punctuation
    text = re.sub(r'\{\{.*?\}\}', '', text)

    text = text.split()
    text = ' '.join(text)
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)

     # Tokenize text
    tokens = word_tokenize(text)
    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    essential_words = {'not', 'no', 'cannot'}
    custom_stop_words = stop_words - essential_words
    tokens = [word for word in tokens if word not in custom_stop_words]


    # Lemmatize tokens
    lemmatizer = WordNetLemmatizer()
    lemmatized_tokens = [lemmatizer.lemmatize(token,pos='v') for token in tokens]
    lemmatized_tokens = [lemmatizer.lemmatize(token, pos ='v') for token in tokens]
    lemmatized_tokens = [lemmatizer.lemmatize(token, pos ='a') for token in tokens]
    lemmatized_tokens = [lemmatizer.lemmatize(token, pos ='r') for token in tokens]
    lemmatized_tokens = [lemmatizer.lemmatize(token, pos ='s') for token in tokens]
    lemmatized_tokens = [lemmatizer.lemmatize(token, pos ='n') for token in tokens]

    # Join tokens back into a string
    cleaned_text = ' '.join(lemmatized_tokens)

    # Optional: Spell correction (can slow down processing)
    cleaned_text = str(TextBlob(cleaned_text).correct()) # Now TextBlob is defined

    # # Spell correction (optional - slow on large datasets)
    # text = str(TextBlob(text).correct())

    return cleaned_text

# ========== IMPORTS & SETUP ========== #
import re
import string
import joblib
import numpy as np
import tensorflow as tf
from transformers import BertTokenizer, TFBertForSequenceClassification
from nltk.corpus import stopwords, wordnet
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
import contractions
from textblob import TextBlob

# ========== COMPONENT LOADING ========== #
# Load preprocessing components
tfidf_vectorizer = joblib.load("/content/drive/MyDrive/models4/tfidf_vectorizer.pkl")
label_encoder = joblib.load("/content/drive/MyDrive/models2/label_encoder.pkl")

# Load ML models
ml_models = {
    "Logistic Regression": joblib.load("/content/drive/MyDrive/models4/Logistic Regression.pkl"),
    "SVM": joblib.load("/content/drive/MyDrive/models4/SVM.pkl"),
    "SGD": joblib.load("/content/drive/MyDrive/models4/SGD.pkl"),
    "Random Forest": joblib.load("/content/drive/MyDrive/models2/Random Forest.pkl"),
    "Na√Øve Bayes": joblib.load("/content/drive/MyDrive/models4/Na√Øve Bayes.pkl")
}

# Load DL components
tokenizer_bert = BertTokenizer.from_pretrained("/content/drive/MyDrive/models2/bert_tokenizer_10")
bert_model = TFBertForSequenceClassification.from_pretrained("/content/drive/MyDrive/models2/bert_model_10")
lstm_model = tf.keras.models.load_model("/content/drive/MyDrive/models2/lstm_model.h5")
with open("/content/drive/MyDrive/models2/tokenizer.pkl", "rb") as handle:
    lstm_tokenizer = pickle.load(handle)

lstm_model = tf.keras.models.load_model("/content/drive/MyDrive/models2/lstm_model.h5")
max_length = 100  # Adjust based on your model's input size


# ========== TEXT PREPROCESSING ========== #
def clean_text_advanced(text):
    """Enhanced text cleaning pipeline"""
    # Contraction expansion
    text = contractions.fix(text)

    # Text normalization
    text = text.lower()
    text = re.sub(r'\{\{.*?\}\}', '', text)
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)

    # Tokenization and stopword removal
    tokens = word_tokenize(text)
    stop_words = set(stopwords.words('english')) - {'not', 'no', 'cannot'}
    tokens = [word for word in tokens if word not in stop_words]

    # Lemmatization
    lemmatizer = WordNetLemmatizer()
    lemmatized_tokens = []
    for token in tokens:
        for pos in [wordnet.VERB, wordnet.ADJ, wordnet.ADV, wordnet.NOUN]:
            lemmatized = lemmatizer.lemmatize(token, pos=pos)
            if lemmatized != token:
                break
        lemmatized_tokens.append(lemmatized)

    # Spell correction (optional)
    cleaned_text = ' '.join(lemmatized_tokens)
    return str(TextBlob(cleaned_text).correct())

# ========== PREDICTION ENGINE ========== #
def apply_dynamic_thresholding(probabilities):
    """Dynamic thresholding with label mapping"""
    categories = label_encoder.classes_
    sorted_indices = np.argsort(probabilities)[::-1]
    sorted_probs = np.array(probabilities)[sorted_indices]
    sorted_cats = [categories[i] for i in sorted_indices]

    main_category = sorted_cats[0]
    additional = []
    high_conf_indices = [0]

    # Rule 1: High-confidence chain
    for i in range(1, len(sorted_probs)):
        if sorted_probs[i] >= 0.5 and (sorted_probs[i-1] - sorted_probs[i]) <= 0.2:
            high_conf_indices.append(i)
        else:
            break

    # Rule 2: Low-confidence clusters
    low_conf_probs = [(prob, idx) for idx, prob in enumerate(sorted_probs)
                     if (prob < 0.5 and prob > 0.1 and idx not in high_conf_indices)]

    # Cluster detection logic
    clusters = []
    current_cluster = []
    for prob, idx in low_conf_probs:
        if not current_cluster:
            current_cluster.append((prob, idx))
        else:
            if current_cluster[-1][0] - prob <= 0.1:
                current_cluster.append((prob, idx))
            else:
                clusters.append(current_cluster)
                current_cluster = [(prob, idx)]
    if current_cluster:
        clusters.append(current_cluster)

    # Cluster selection
    clusters.sort(key=lambda x: len(x), reverse=True)
    selected_low_conf = []
    for cluster in clusters:
        selected_low_conf.extend([idx for (prob, idx) in cluster])
        if len(selected_low_conf) >= 4 - len(high_conf_indices):
            break

    # Final selection
    all_selected = high_conf_indices + selected_low_conf[:4 - len(high_conf_indices)]
    additional = [(sorted_cats[idx], sorted_probs[idx]) for idx in all_selected if idx != 0]

    return main_category, additional

# ========== PREDICTION PIPELINES ========== #
def ml_pipeline(model, text):
    cleaned_text = clean_text_advanced(text)
    text_tfidf = tfidf_vectorizer.transform([cleaned_text])

    if hasattr(model, "predict_proba"):
        probs = model.predict_proba(text_tfidf)[0]
    else:
        scores = model.decision_function(text_tfidf)[0]
        probs = 1 / (1 + np.exp(-scores))

    main, additional = apply_dynamic_thresholding(probs)
    return format_prediction(main, additional)

def lstm_pipeline(text):
    """End-to-end LSTM prediction pipeline"""
    cleaned_text = clean_text_advanced(text)
    sequence = tokenizer.texts_to_sequences([cleaned_text])
    padded = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=200)
    probs = lstm_model.predict(padded, verbose=0)[0]
    main, additional = apply_dynamic_thresholding(probs)
    return format_prediction(main, additional)

def bert_pipeline(text):
    """End-to-end BERT prediction pipeline"""
    cleaned_text = clean_text_advanced(text)
    inputs = tokenizer_bert(cleaned_text,
                          return_tensors="tf",
                          padding=True,
                          truncation=True,
                          max_length=512)
    outputs = bert_model(**inputs)
    probs = tf.nn.softmax(outputs.logits, axis=-1).numpy()[0]
    main, additional = apply_dynamic_thresholding(probs)
    return format_prediction(main, additional)

# ========== RESULT FORMATTING ========== #
def format_prediction(main, additional):
    """Standardized prediction formatting"""
    additional_str = ", ".join([f"{label} ({prob:.2f})" for label, prob in additional[1:]])
    if additional_str:
        return f"Prediction: The main category of your ticket is under '{main}', and your ticket may also need to be considered in these other parts: {additional_str}."
    else:
        return f"Prediction: The main category of your ticket is under '{main}'."

# ========== EXECUTION ========== #
if __name__ == "__main__":
    # Suppress unnecessary warnings
    tf.get_logger().setLevel('ERROR')

    # Test text
    test_text = "I want to cancel my order and get a refund because I never received it."

    # Run all pipelines
    pipelines = {
        "Logistic Regression": lambda t: ml_pipeline(ml_models["Logistic Regression"], t),
        "SVM": lambda t: ml_pipeline(ml_models["SVM"], t),
        "SGD": lambda t: ml_pipeline(ml_models["SGD"], t),
        "Random Forest": lambda t: ml_pipeline(ml_models["Random Forest"], t),
        "Na√Øve Bayes": lambda t: ml_pipeline(ml_models["Na√Øve Bayes"], t),
        "LSTM": lstm_pipeline,
        "BERT": bert_pipeline
    }

    for model_name, pipeline in pipelines.items():
        try:
            print(f"\n=== {model_name} Prediction ===")
            print(pipeline(test_text))
        except Exception as e:
            print(f"Error in {model_name}: {str(e)}")

import os
import re
import string
import joblib
import numpy as np
import tensorflow as tf
import contractions
from textblob import TextBlob
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from transformers import BertTokenizer, TFBertForSequenceClassification



# Explicit function wrappers for ML pipelines (No lambdas)
def logistic_regression_pipeline(text):
    return ml_pipeline(ml_models["Logistic Regression"], text)

def svm_pipeline(text):
    return ml_pipeline(ml_models["SVM"], text)

def sgd_pipeline(text):
    return ml_pipeline(ml_models["SGD"], text)

def random_forest_pipeline(text):
    return ml_pipeline(ml_models["Random Forest"], text)

def naive_bayes_pipeline(text):
    return ml_pipeline(ml_models["Na√Øve Bayes"], text)

# Dictionary of Pipelines
full_pipeline = {
    "Logistic Regression Pipeline": logistic_regression_pipeline,
    "SVM Pipeline": svm_pipeline,
    "SGD Pipeline": sgd_pipeline,
    "Random Forest Pipeline": random_forest_pipeline,
    "Na√Øve Bayes Pipeline": naive_bayes_pipeline,
    "LSTM Pipeline": lstm_pipeline,
    "BERT Pipeline": bert_pipeline
}


# ‚úÖ Save Each Pipeline Separately
os.makedirs("/content/drive/MyDrive/models4/", exist_ok=True)
joblib.dump(logistic_regression_pipeline, "/content/drive/MyDrive/models4/logistic_regression_pipeline.pkl")
joblib.dump(svm_pipeline, "/content/drive/MyDrive/models4/svm_pipeline.pkl")
joblib.dump(sgd_pipeline, "/content/drive/MyDrive/models4/sgd_pipeline.pkl")
joblib.dump(random_forest_pipeline, "/content/drive/MyDrive/models4/random_forest_pipeline.pkl")
joblib.dump(naive_bayes_pipeline, "/content/drive/MyDrive/models4/naive_bayes_pipeline.pkl")
joblib.dump(lstm_pipeline, "/content/drive/MyDrive/models4/lstm_pipeline.pkl")
joblib.dump(bert_pipeline, "/content/drive/MyDrive/models4/bert_pipeline.pkl")

print("‚úÖ All pipelines saved separately!")

# ‚úÖ Load Pipelines (To Verify)
loaded_logistic_regression_pipeline = joblib.load("/content/drive/MyDrive/models4/logistic_regression_pipeline.pkl")
loaded_svm_pipeline = joblib.load("/content/drive/MyDrive/models4/svm_pipeline.pkl")
loaded_sgd_pipeline = joblib.load("/content/drive/MyDrive/models4/sgd_pipeline.pkl")
loaded_random_forest_pipeline = joblib.load("/content/drive/MyDrive/models4/random_forest_pipeline.pkl")
loaded_naive_bayes_pipeline = joblib.load("/content/drive/MyDrive/models4/naive_bayes_pipeline.pkl")
loaded_lstm_pipeline = joblib.load("/content/drive/MyDrive/models4/lstm_pipeline.pkl")
loaded_bert_pipeline = joblib.load("/content/drive/MyDrive/models4/bert_pipeline.pkl")

# Test Pipelines
test_text = "I want to cancel my order and get a refund because I never received it."

print("\nLogistic Regression:", loaded_logistic_regression_pipeline(test_text))
print("\nSVM:", loaded_svm_pipeline(test_text))
print("\nSGD:", loaded_sgd_pipeline(test_text))
print("\nRandom Forest:", loaded_random_forest_pipeline(test_text))
print("\nNa√Øve Bayes:", loaded_naive_bayes_pipeline(test_text))
print("\nLSTM Prediction:", loaded_lstm_pipeline(test_text))
print("\nBERT Prediction:", loaded_bert_pipeline(test_text))